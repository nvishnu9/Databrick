{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c3099ca-cc13-41db-a6d6-23244022c651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Introducing Data Ingestion\n",
    "Data ingestion is the process of loading data from files into Delta Lake tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f3ad8f6-aad6-44d9-bdbb-d2b2c6b6de24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Challenge in Traditional Pipelines**\n",
    "\n",
    "- Every run reprocesses all files (even those already loaded).\n",
    "- Leads to:\n",
    "  - Higher compute costs.\n",
    "  - Longer runtimes.\n",
    "  - Extra deduplication work, especially with large datasets.\n",
    "\n",
    "**Solution: Incremental Data Ingestion**\n",
    "\n",
    "- Loads only newly arrived files since the last ingestion cycle.\n",
    "- Benefits:\n",
    "  - Faster processing.\n",
    "  - Lower resource usage.\n",
    "  - Avoids reprocessing old data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c18ed87-96c1-47f8-bcc6-8fe89eb12483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Databricks offers two primary mechanisms:\n",
    "**1. COPY INTO**\n",
    "\n",
    "**2. Auto Loader**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2f6d077-24bf-4323-adbb-992dccb5374d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## COPY INTO Command\n",
    "  - A SQL command that loads data from a file location into a Delta table.\n",
    "  - Key Characteristics:\n",
    "    - **Idempotent**: Running it multiple times won’t reprocess files already ingested.\n",
    "    - **Incremental**: Each run loads only new files detected in the source location.\n",
    "\n",
    "**COPY INTO Syntax**\n",
    "\n",
    "```\n",
    "COPY INTO <target_table>\n",
    "FROM '<path_to_files>'\n",
    "FILEFORMAT = <format>\n",
    "FORMAT_OPTIONS (<format_options>)\n",
    "COPY_OPTIONS (<copy_options>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12bf110f-4406-469e-8611-2502e358ac75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Generate-Sample-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cbe8cd5-7bbf-4c81-b9c4-4979042d371c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\"dataingestion/product/\", True)\n",
    "generate_product_csv(num_records=10)\n",
    "dbutils.fs.ls(\"/dataingestion/product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5549a643-e5c6-4d2a-a044-f890775f82c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS product_delta;\n",
    "CREATE TABLE product_delta (\n",
    "  product_id STRING,\n",
    "  product_name STRING,\n",
    "  category STRING,\n",
    "  price STRING,\n",
    "  created_at STRING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c5e0f9-d769-4856-a854-da3064c83c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM product_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726c1cf0-6f7a-4155-8dc4-f40a8c3245fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def copyinto():\n",
    "    spark.sql(\n",
    "        \"\"\"\n",
    "        COPY INTO product_delta\n",
    "        FROM '/dataingestion/product'\n",
    "        FILEFORMAT = CSV\n",
    "        FORMAT_OPTIONS (\n",
    "        'header' = 'true',\n",
    "        'delimiter' = ','\n",
    "        )\n",
    "        COPY_OPTIONS (\n",
    "        'onBadRecords' = 'skip',\n",
    "        'mergeSchema' = 'true'\n",
    "        )\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2771da00-2286-4fed-8db9-3d913019fbab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copyinto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab21ed24-58a4-4df0-9e93-0f61a8d272b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM product_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a688665d-0241-4f13-85ea-56427d57bcfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_product_csv(num_records=5)\n",
    "display(dbutils.fs.ls(\"/dataingestion/product\"))\n",
    "spark.sql(\"SELECT count(1) FROM product_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c18d444-22fc-4164-a1b1-64a4eb544bc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copyinto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de08132-b67f-47f2-92b2-c0b4360e84e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT count(1) FROM product_delta\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f18c59a8-ffa3-4817-8afb-a0dcc97e0d8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Auto Loader\n",
    "- Uses Spark Structured Streaming to continuously detect and load new files using readStream and writeStream.\n",
    "- Key features:\n",
    "  - Highly scalable: Can process billions of files.\n",
    "  - High ingestion throughput: Supports millions of files per hour.\n",
    "  - Checkpointing ensures exactly-once processing and recovery after failures.\n",
    "  - Supports automatic schema inference and evolution.2.\n",
    "\n",
    "**Basic Usage Example:**\n",
    "```\n",
    "spark.readStream \\\n",
    "  .format(\"cloudFiles\") \\\n",
    "  .option(\"cloudFiles.format\", \"<source_format>\") \\\n",
    "  .load(\"/path/to/files\") \\\n",
    "  .writeStream \\\n",
    "  .option(\"checkpointLocation\", \"<checkpoint_path>\") \\\n",
    "  .table(\"<table_name>\")\n",
    "```\n",
    "\n",
    "**Here’s how this works step by step:**\n",
    "\n",
    "- You set .format(\"cloudFiles\") to activate Auto Loader.\n",
    "- Use cloudFiles.format to specify the format of incoming files (e.g., csv, json, parquet).\n",
    "- The .load() call defines the source folder Auto Loader monitors for new files.\n",
    "- .writeStream writes the ingested data to the target table or location.\n",
    "- checkpointLocation records progress so processing can resume if interrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb5ddceb-a444-440e-8216-5adc4372b3fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Schema Management\n",
    "Auto Loader includes built-in schema detection to simplify working with new data:\n",
    "\n",
    "- **Automatic Schema Inference:**\n",
    "  \n",
    "  Auto Loader can detect the schema without requiring you to define it up front.\n",
    "\n",
    "- **Schema Evolution:**\n",
    "  \n",
    "  If new columns appear in incoming data, Auto Loader can automatically update the schema of the destination table.\n",
    "\n",
    "  To enable this, set: `.option(\"mergeSchema\", \"true\")`\n",
    "\n",
    "- **Schema Storage:**\n",
    "  \n",
    "  To avoid re-inferring schema every time your stream starts (which can be slow), you can save the inferred schema to a dedicated location: `.option(\"cloudFiles.schemaLocation\", \"<schema_storage_path>\")`\n",
    "\n",
    "- **Data Type Inference for Non-Typed Formats**\n",
    "  > Important: Behavior depends on your file format:\n",
    "\n",
    "  - **Typed formats** (e.g., Parquet): Auto Loader reads column types from the file metadata.\n",
    "\n",
    "  - **Untyped formats** (e.g., CSV, JSON): By default, all columns are inferred as STRING.\n",
    "\n",
    "  To automatically detect proper data types (e.g., INTEGER, DOUBLE), enable this option: `.option(\"cloudFiles.inferColumnTypes\", \"true\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12b8020d-1ec0-469f-81fa-16103ac6cb6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example with All Recommended Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "107bd7be-0d3c-45a9-bb1c-f7bfc9c12dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\"/dataingestion\", True)\n",
    "spark.sql(\"DROP TABLE IF EXISTS new_product_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97defcda-fe72-4e29-8b66-e476b5480f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_product_csv(num_records=10)\n",
    "display(dbutils.fs.ls(\"/dataingestion/product\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebe9b12-dd88-4304-8229-8f9392cd0bc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def autoLoadFunc() :\n",
    "  (spark.readStream\n",
    "  .format(\"cloudFiles\")\n",
    "  .option(\"cloudFiles.format\", \"csv\")\n",
    "  .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "  .option(\"cloudFiles.schemaLocation\", \"/dataingestion/schema\")\n",
    "  .load(\"/dataingestion/product\")\n",
    "  .writeStream\n",
    "  .option(\"checkpointLocation\", \"/dataingestion/checkpoint\")\n",
    "  .option(\"mergeSchema\", \"true\")\n",
    "  .outputMode(\"append\")\n",
    "  .table(\"new_product_delta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21174820-6978-4c60-8426-566ea4ea1ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "autoLoadFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f50d18d-ce6b-4fed-bbc4-56fc72978af6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1751898362838}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE new_product_delta;\n",
    "-- DESCRIBE EXTENDED new_product_delta;\n",
    "-- SHOW TABLES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a3ff1b6-628e-404e-820e-5b4815ce6e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT count(1) FROM new_product_delta\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f77c5f0-63c3-4eb3-ab42-ae80187641e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_product_csv(num_records=5)\n",
    "display(dbutils.fs.ls(\"/dataingestion/product\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ea6400-a9f4-4c84-91c2-d54a663fac24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM new_product_delta\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "400a51b6-0cc6-4620-a6ba-18b579aa307d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How does Auto Loader schema evolution work?\n",
    "Auto Loader detects the addition of new columns as it processes your data. When Auto Loader detects a new column, the stream stops with an **`UnknownFieldException`**. Before your stream throws this error, Auto Loader performs schema inference on the latest micro-batch of data and updates the schema location with the latest schema by merging new columns to the end of the schema. The data types of existing columns remain unchanged.\n",
    "\n",
    "Databricks recommends configuring Auto Loader streams with Lakeflow Jobs to restart automatically after such schema changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44afdb7-8c62-4ca6-ac48-49ff0c44d680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_product_csv_new(num_records=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18ea8e8-d9f5-4aa7-8b88-594012366d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM new_product_delta\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8dafad4-7950-450a-bf59-1f389c63d2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "autoLoadFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d3e2dc9-ff3e-4061-9156-6d6f8ffbb485",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1751898472976}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM new_product_delta\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6b72f89-ed02-44bf-9fb5-ce7312afd3e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### What is _rescued_data?\n",
    "_rescued_data is a special column automatically added by Auto Loader (and Spark schema inference in general) when:\n",
    "\n",
    "- Your incoming data has unexpected columns (i.e., columns not present in the table schema)\n",
    "- Or some data rows don’t match the expected schema (e.g., extra fields, unparseable fields)\n",
    "\n",
    "Instead of failing or dropping the unexpected data, Spark will capture it in this _rescued_data column as a JSON string so nothing is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c2ba8d-4d7e-4a71-8a8b-6bd26a652aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY new_product_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3981fab3-7e7f-4b9a-9caa-b93d1e9cf969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543844c0-5c57-48eb-9d90-7210868d641f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print & Stop all active queries\n",
    "for q in spark.streams.active:\n",
    "    print(f\"Name: {q.name}, Id: {q.id}, IsActive: {q.isActive}\")\n",
    "    if q.isActive:\n",
    "        q.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118f2e93-79f9-4f6e-b6b9-db0f87d040c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS product_delta;\n",
    "DROP TABLE IF EXISTS new_product_delta;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c9b2e7-45f2-48f2-a77d-7f122160b6e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs rm -r /dataingestion"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4741119897180744,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data-Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
