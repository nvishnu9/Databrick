{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dafa094-c1df-4545-84a9-9c72c449dcfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542395ad-58b3-4c3e-b454-dae8d8744f04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### The Data Source\n",
    "The scenario for this exercise is based on observations of penguins in Antarctica, with the goal of training a machine learning model to predict the species of an observed penguin based on its location and body measurements.\n",
    "\n",
    "The data itself consists of measurements of the following details of penguins that have been observed in Antarctica:\n",
    "\n",
    "- **Island**: The island in Antarctica where the penguin was observed.\n",
    "- **CulmenLength**: The length in mm of the penguin’s culmen (bill).\n",
    "- **CulmenDepth**: The depth in mm of the penguin’s culmen.\n",
    "- **FlipperLength**: The length in mm of the penguin’s flipper.\n",
    "- **BodyMass**: The body mass of the penguin in grams.\n",
    "- **Species**: An integer value that represents the species of the penguin:\n",
    "  - 0: Adelie\n",
    "  - 1: Gentoo\n",
    "  - 2: Chinstrap\n",
    "\n",
    "Our goal in this project is to use the observed characteristics of a penguin (its features) in order to predict its species \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de0f97b-e4b5-40f1-b357-81adf651e1dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../PySpark/DatasetSourcePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4694b20-97a4-40c6-8253-dbd35f148bff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explore and clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d205bdfb-a95b-486c-b0de-a8f379cdfa05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = sourcePath + \"/dataset/penguins.csv\"\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ddaed2e-0b85-4fe9-8973-74fda89e9adf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Remove the rows with incomplete data by using the dropna method, and to apply appropriate data types to the data by using the select method with the col and astype functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90052422-4720-461b-a9f0-12ee51398f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = df.dropna().select(col(\"Island\").astype(\"string\"),\n",
    "                           col(\"CulmenLength\").astype(\"float\"),\n",
    "                          col(\"CulmenDepth\").astype(\"float\"),\n",
    "                          col(\"FlipperLength\").astype(\"float\"),\n",
    "                          col(\"BodyMass\").astype(\"float\"),\n",
    "                          col(\"Species\").astype(\"int\")\n",
    "                          )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf1cf03a-a41a-4195-ae22-54ce9b0b82ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Split the data\n",
    "- The label we want to predict is a category or class (specifically, the penguin species), so we’ll train a classification model.\n",
    "- Classification (like regression, which predicts numeric values) is a type of supervised machine learning. In supervised learning, the training data includes known label values we want to predict.\n",
    "- Training a model means fitting an algorithm to this data so it can learn how the input features relate to the label.\n",
    "- After training, we can use the model to predict the label for new observations where we only know the feature values.\n",
    "- To make sure the model is reliable, we don’t train on all the data. Instead, we hold back a portion of data with known labels so we can test the model’s predictions and measure its accuracy.\n",
    "- To do this, we split the dataset into two random subsets:\n",
    "  - 70% of the data for training the model.\n",
    "  - 30% of the data for testing how well it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7337e3-de2d-4e73-ae6a-153887ac0d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2785c6d1-d92a-4d9b-9edc-e10f9ce55978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Perform feature engineering\n",
    "**Encode categorical features**\n",
    "\n",
    "- Machine learning needs features as numbers, not strings.\n",
    "- Categorical data like island names must be converted to numeric values.\n",
    "- We use StringIndexer in Spark MLlib to assign each category a unique integer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc91d9b-2361-46af-9139-26ee8ea84ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Island\", outputCol=\"IslandIdx\")\n",
    "indexedData = indexer.fit(train).transform(train).drop(\"Island\")\n",
    "display(indexedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a13357-4060-4be8-9f71-01b40d8fc2e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Normalize (scale) numeric features**\n",
    "\n",
    "- Numeric columns (e.g., CulmenLength, BodyMass) have different scales.\n",
    "- Large values can dominate model training and bias predictions.\n",
    "- To fix this, we normalize all numeric features to the same scale (like 0.0 to 1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90cdee02-8f02-485d-a281-495d6c569f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "# Create a vector column containing all numeric features\n",
    "numericFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "numericColVector = VectorAssembler(inputCols=numericFeatures, outputCol=\"numericFeatures\")\n",
    "vectorizedData = numericColVector.transform(indexedData)\n",
    "   \n",
    "# Use a MinMax scaler to normalize the numeric values in the vector\n",
    "minMax = MinMaxScaler(inputCol = numericColVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "scaledData = minMax.fit(vectorizedData).transform(vectorizedData)\n",
    "   \n",
    "# Display the data with numeric feature vectors (before and after scaling)\n",
    "compareNumerics = scaledData.select(\"numericFeatures\", \"normalizedFeatures\")\n",
    "display(compareNumerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8db2fa9b-9c6b-4b3d-be62-0aa1b5881adc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare features and labels for training\n",
    "\n",
    "The features vector contains five values (the encoded island and the normalized culmen length, culmen depth, flipper length, and body mass). The label contains a simple integer code that indicates the class of penguin species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0933e7b2-07dd-48c3-ad3c-dfc8113f67f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "featVect = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"featuresVector\")\n",
    "preppedData = featVect.transform(scaledData)[col(\"featuresVector\").alias(\"features\"), col(\"Species\").alias(\"label\")]\n",
    "display(preppedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06bde36-1b0e-4843-b192-6e1c215148b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train a machine learning model\n",
    "\n",
    "- With prepared data, you can train a model using an algorithm that links features to labels.\n",
    "- Since you’re predicting a category, use a classification algorithm.\n",
    "- A common choice is logistic regression, which calculates class probabilities by finding optimal coefficients.\n",
    "- You train the model by fitting logistic regression to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "404a00bd-76f6-4ebd-825c-33d521c7c068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
    "model = lr.fit(preppedData)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cb7b887-f46b-4ce7-97a0-38c0af1631df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Test the model\n",
    "\n",
    "- Use the held-back test data to evaluate the model.\n",
    "- First, apply the same feature engineering (encode categories, normalize numbers).\n",
    "- Then, predict labels on the test data.\n",
    "- Finally, compare predictions to actual labels to measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20312336-5350-4b59-8155-16c17d7a120c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "indexedTestData = indexer.fit(test).transform(test).drop(\"Island\")\n",
    "vectorizedTestData = numericColVector.transform(indexedTestData)\n",
    "scaledTestData = minMax.fit(vectorizedTestData).transform(vectorizedTestData)\n",
    "preppedTestData = featVect.transform(scaledTestData)[col(\"featuresVector\").alias(\"features\"), col(\"Species\").alias(\"label\")]\n",
    "   \n",
    "# Get predictions\n",
    "prediction = model.transform(preppedTestData)\n",
    "predicted = prediction.select(\"features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"label\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a36b0b00-4a0a-429d-929f-3752506be80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The results include the following columns:\n",
    "\n",
    "- **features**: The prepared features data from the test dataset.\n",
    "- **probability**: The probability calculated by the model for each class. This consists of a vector containing three probability values (because there are three classes) which add up to a total of 1.0 (its assumed that there’s a 100% probability that the penguin belongs to one of the three species classes).\n",
    "- **prediction**: The predicted class label (the one with the highest probability).\n",
    "- **trueLabel**: The actual known label value from the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "650a1c37-97da-4c62-b11d-3938079118ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Get evaluation metrics for a classification model based on the results from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec939be-6317-4c74-9c43-d72b9cd8cee8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "   \n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "   \n",
    "# Individual class metrics\n",
    "labels = [0,1,2]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighted (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e64c59c-de61-4e13-8c1f-535ddf4a69a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The evaluation metrics that are calculated for multiclass classification include:\n",
    "\n",
    "- **Accuracy**: The proportion of overall predictions that were correct.\n",
    "- Per-class metrics:\n",
    "  - **Precision**: The proportion of predictions of this class that were correct.\n",
    "  - **Recall**: The proportion of actual instances of this class that were correctly predicted.\n",
    "  - **F1 score**: A combined metric for precision and recall\n",
    "- Combined (weighted) precision, recall, and F1 metrics for all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dba63a81-07a4-469b-89a9-de8047433a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Use a pipeline\n",
    "\n",
    "- You trained the model by doing feature engineering and then fitting the algorithm.\n",
    "- To make predictions, you had to repeat the same transformations on test data.\n",
    "- A better approach is to create a pipeline that combines all data preparation steps and the model into one reusable workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560d37bb-ef68-445e-8c42-03ab3c986998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "   \n",
    "catFeature = \"Island\"\n",
    "numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "   \n",
    "# Define the feature engineering and model training algorithm steps\n",
    "catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = LogisticRegression(labelCol=\"Species\", featuresCol=\"Features\", maxIter=10, regParam=0.3)\n",
    "   \n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a77b698-8902-45f2-b5e0-4e2f676b52fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Apply the pipeline to the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba3e6c4-a204-425e-a118-2a75958817f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Species\").alias(\"trueLabel\"))\n",
    "display(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "267af769-96cd-4058-a32f-33121bb0c5d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Try a different algorithm\n",
    "Decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee35b5a-2290-4ef4-b9db-0e99e22f1efe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "   \n",
    "catFeature = \"Island\"\n",
    "numFeatures = [\"CulmenLength\", \"CulmenDepth\", \"FlipperLength\", \"BodyMass\"]\n",
    "   \n",
    "# Define the feature engineering and model steps\n",
    "catIndexer = StringIndexer(inputCol=catFeature, outputCol=catFeature + \"Idx\")\n",
    "numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "featureVector = VectorAssembler(inputCols=[\"IslandIdx\", \"normalizedFeatures\"], outputCol=\"Features\")\n",
    "algo = DecisionTreeClassifier(labelCol=\"Species\", featuresCol=\"Features\", maxDepth=10)\n",
    "   \n",
    "# Chain the steps as stages in a pipeline\n",
    "pipeline = Pipeline(stages=[catIndexer, numVector, numScaler, featureVector, algo])\n",
    "   \n",
    "# Use the pipeline to prepare data and fit the model algorithm\n",
    "model = pipeline.fit(train)\n",
    "print (\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69925043-1300-4fe1-acce-70e3887c397f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Use the new pipeline with the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff85cad-3425-4855-a90c-b4299c620f17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"Features\", \"probability\", col(\"prediction\").astype(\"Int\"), col(\"Species\").alias(\"trueLabel\"))\n",
    "   \n",
    "# Generate evaluation metrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Species\", predictionCol=\"prediction\")\n",
    "   \n",
    "# Simple accuracy\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName:\"accuracy\"})\n",
    "print(\"Accuracy:\", accuracy)\n",
    "   \n",
    "# Class metrics\n",
    "labels = [0,1,2]\n",
    "print(\"\\nIndividual class metrics:\")\n",
    "for label in sorted(labels):\n",
    "    print (\"Class %s\" % (label))\n",
    "   \n",
    "    # Precision\n",
    "    precision = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                                    evaluator.metricName:\"precisionByLabel\"})\n",
    "    print(\"\\tPrecision:\", precision)\n",
    "   \n",
    "    # Recall\n",
    "    recall = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                             evaluator.metricName:\"recallByLabel\"})\n",
    "    print(\"\\tRecall:\", recall)\n",
    "   \n",
    "    # F1 score\n",
    "    f1 = evaluator.evaluate(prediction, {evaluator.metricLabel:label,\n",
    "                                         evaluator.metricName:\"fMeasureByLabel\"})\n",
    "    print(\"\\tF1 Score:\", f1)\n",
    "   \n",
    "# Weighed (overall) metrics\n",
    "overallPrecision = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedPrecision\"})\n",
    "print(\"Overall Precision:\", overallPrecision)\n",
    "overallRecall = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedRecall\"})\n",
    "print(\"Overall Recall:\", overallRecall)\n",
    "overallF1 = evaluator.evaluate(prediction, {evaluator.metricName:\"weightedFMeasure\"})\n",
    "print(\"Overall F1 Score:\", overallF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8290c50d-17a8-4bc5-8c13-882d3dc6f9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c1aec00-3e28-421d-a073-cec1b5559828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"/models1/penguin.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f37690-a7d6-4844-ac7e-3b05ca9496ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the model and use it to predict the species for a new penguin observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "964144fa-727e-48b6-9ca7-3c66833fc15d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "persistedModel = PipelineModel.load(\"/models1/penguin.model\")\n",
    "   \n",
    "newData = spark.createDataFrame ([{\"Island\": \"Biscoe\",\n",
    "                                  \"CulmenLength\": 47.6,\n",
    "                                  \"CulmenDepth\": 14.5,\n",
    "                                  \"FlipperLength\": 215,\n",
    "                                  \"BodyMass\": 5400}])\n",
    "   \n",
    "   \n",
    "predictions = persistedModel.transform(newData)\n",
    "display(predictions.select(\"Island\", \"CulmenDepth\", \"CulmenLength\", \"FlipperLength\", \"BodyMass\", col(\"prediction\").alias(\"PredictedSpecies\")))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Train-ML-Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
