{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c150310d-50d8-474a-b5c5-6777c5ddc13f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Reading Data - JSON Files\n",
    "\n",
    "**Technical Accomplishments:**\n",
    "- Read data from:\n",
    "  * JSON without a Schema\n",
    "  * JSON with a Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "001274ea-4fdb-46b3-ba5a-2fb6c10732e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da887034-4e75-400a-87a8-d2b99c16eef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "214a2094-2f4d-45f8-9943-be6b26df5b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Read Json Data\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d08bdfe-90e5-4dcf-a619-04966b39dca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading from JSON w/ InferSchema\n",
    "\n",
    "Reading in JSON isn't that much different than reading in CSV files.\n",
    "\n",
    "Let's start with taking a look at all the different options that go along with reading in JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c78f975-50f7-45f7-99fe-13abf6f4a169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### JSON Lines\n",
    "\n",
    "Much like the CSV reader, the JSON reader also assumes...\n",
    "* That there is one JSON object per line and...\n",
    "* That it's delineated by a new-line.\n",
    "\n",
    "This format is referred to as **JSON Lines** or **newline-delimited JSON** \n",
    "\n",
    "More information about this format can be found at <a href=\"http://jsonlines.org/\" target=\"_blank\">http://jsonlines.org</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2895628-1dbc-486d-ac45-22461d40f6ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### The Data Source\n",
    "* For this exercise, we will be using the file called **snapshot-2016-05-26.json**\n",
    "* The data represents a set of edits to Wikipedia articles captured in May of 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcce3f18-99ff-4617-9a25-15aa131f2b93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../DatasetSourcePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19fdef1b-832d-41bc-9de2-9e47d9b77aa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read The JSON File\n",
    "\n",
    "The command to read in JSON looks very similar to that of CSV.\n",
    "\n",
    "In addition to reading the JSON file, we will also print the resulting schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03dbf79-0824-4430-b39e-a15151dba170",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jsonFile = sourcePath + \"/dataset/snapshot-2016-05-26.json\"\n",
    "jsonFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfaf2d20-1cfb-477c-84a5-4bd4b8c4d32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs head 'abfss://files@storage33e.dfs.core.windows.net/dataset/snapshot-2016-05-26.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9782bb2e-dd5c-40b2-9619-d210477adff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jsonFile = sourcePath + \"/dataset/snapshot-2016-05-26.json\"\n",
    "\n",
    "wikiEditsDF = (spark.read           # The DataFrameReader\n",
    "    .option(\"inferSchema\", \"true\")  # Automatically infer data types & column names\n",
    "    .json(jsonFile)                 # Creates a DataFrame from JSON after reading in the file\n",
    " )\n",
    "wikiEditsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8be58042-e54e-458e-801d-385c43f80422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "With our DataFrame created, we can now take a peak at the data.\n",
    "\n",
    "But to demonstrate a unique aspect of JSON data (or any data with embedded fields), we will first create a temporary view and then view the data via SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a8eae7b-a783-4d77-a98f-92c621eb497f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext sparksql_magic\n",
    "# %config SparkSql.limit=5\n",
    "\n",
    "# %%sparksql - Magic Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fb99785-2dfc-47e4-a4f1-5f40d0f32b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a view called wiki_edits\n",
    "wikiEditsDF.createOrReplaceTempView(\"wiki_edits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49a9ce19-b6d7-42a8-9bf7-495b1958c96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And now we can take a peak at the data with simple SQL SELECT statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40d63970-6044-47d3-af49-29a2a004b50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM wiki_edits\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d6b12d5-8809-4db5-ad03-493267722b4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM wiki_edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0e6839-4d8f-45e1-a2bd-c05d33395828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notice the **geocoding** column has embedded data.\n",
    "\n",
    "But we can also reference the sub-fields directly as we see in the following SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b157edc8-d588-42fa-87df-805c7e08442e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT channel, page, geocoding.city, geocoding.latitude, geocoding.longitude \n",
    "FROM wiki_edits \n",
    "WHERE geocoding.city IS NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc8237fc-bcc6-428a-b186-cb3a615fa8d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Review: Reading from JSON w/ InferSchema\n",
    "\n",
    "While there are similarities between reading in CSV & JSON there are some key differences:\n",
    "* We only need one job even when inferring the schema.\n",
    "* There is no header which is why there isn't a second job in this case - the column names are extracted from the JSON object's attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed1b0794-641b-4c63-92df-6d8046df3ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading from JSON w/ User-Defined Schema\n",
    "\n",
    "To avoid the extra job, we can (just like we did with CSV) specify the schema for the `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf0f157d-08d1-4c9b-b42a-e89b89ae3f01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step #1 - Create the Schema\n",
    "\n",
    "Compared to our CSV example, the structure of this data is a little more complex.\n",
    "\n",
    "Note that we can support complex data types as seen in the field `geocoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "151d7421-8392-49b3-91f1-82e06ddad80b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Required for StructField, StringType, IntegerType, etc.\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "jsonSchema = StructType([\n",
    "  StructField(\"channel\", StringType(), True),\n",
    "  StructField(\"comment\", StringType(), True),\n",
    "  StructField(\"delta\", IntegerType(), True),\n",
    "  StructField(\"flag\", StringType(), True),\n",
    "  StructField(\"geocoding\", StructType([\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"countryCode2\", StringType(), True),\n",
    "    StructField(\"countryCode3\", StringType(), True),\n",
    "    StructField(\"stateProvince\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True)\n",
    "  ]), True),\n",
    "  StructField(\"isAnonymous\", BooleanType(), True),\n",
    "  StructField(\"isNewPage\", BooleanType(), True),\n",
    "  StructField(\"isRobot\", BooleanType(), True),\n",
    "  StructField(\"isUnpatrolled\", BooleanType(), True),\n",
    "  StructField(\"namespace\", StringType(), True),\n",
    "  StructField(\"page\", StringType(), True),\n",
    "  StructField(\"pageURL\", StringType(), True),\n",
    "  StructField(\"timestamp\", StringType(), True),\n",
    "  StructField(\"url\", StringType(), True),\n",
    "  StructField(\"user\", StringType(), True),\n",
    "  StructField(\"userURL\", StringType(), True),\n",
    "  StructField(\"wikipediaURL\", StringType(), True),\n",
    "  StructField(\"wikipedia\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b714f498-c161-44db-b82d-5b71672fbfd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "That was a lot of typing to get our schema!\n",
    "\n",
    "For a small file, manually creating the the schema may not be worth the effort.\n",
    "\n",
    "However, for a large file, the time to manually create the schema may be worth the trade off of a really long infer-schema process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bdcbc85-e0d1-41aa-ae77-1e105a5980c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step #2 - Read in the JSON\n",
    "\n",
    "Next, we will read in the JSON file and once again print its schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06c2cad1-bb95-43ed-88ac-75d4f669437a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark.read            # The DataFrameReader\n",
    "  .schema(jsonSchema)  # Use the specified schema\n",
    "  .json(jsonFile)      # Creates a DataFrame from JSON after reading in the file\n",
    "  .printSchema()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f98768e-1492-4bf9-8364-2bf784b61ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Review: Reading from JSON w/ User-Defined Schema\n",
    "* Just like CSV, providing the schema avoids the extra jobs.\n",
    "* The schema allows us to rename columns and specify alternate data types.\n",
    "* Can get arbitrarily complex in its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "687118e5-d0e9-44d3-92d7-4828da2777ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's take a look at some of the other details of the `DataFrame` we just created for comparison sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f4107e-db4d-4937-80aa-98c27972be65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jsonDF = (spark.read\n",
    "  .schema(jsonSchema)\n",
    "  .json(jsonFile)    \n",
    ")\n",
    "print(\"Partitions: \" + str(jsonDF.rdd.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38fd64f5-9ff0-48bd-ab33-87cbfba128e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And of course we can view that data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a487486e-0bcd-4172-87a9-e56c1396e188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(jsonDF.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "651b9008-f4c1-4e0f-9a10-fdf9fa22a54a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1970257218844254,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "2.Reading Data - JSON",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
