{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca58889b-0eca-48ef-9e93-2d960c764614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# User Define Function\n",
    "A UDF lets you define custom logic that you can apply to your data when built-in functions are not enough.\n",
    "\n",
    "- You write a function in Python, Scala, Java, or R.\n",
    "- Register it with Spark.\n",
    "- Then you can call it like any Spark function in SQL or DataFrame operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8282d8c8-c0f0-48a3-9d20-4c5ed02b8b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Why Use UDFs?\n",
    "**Reasons to use UDFs:**\n",
    "\n",
    "1. **Custom logic**: You can encode business-specific calculations or transformations that are too complex for standard functions.\n",
    "1. **Reusability**: Instead of writing the same code over and over, define the logic once and reuse it.\n",
    "1. **Readability**: Makes complex transformations easier to understand.\n",
    "\n",
    "**When to avoid UDFs:**\n",
    "\n",
    "- UDFs can be **slower** because Spark treats them as a “black box” and can’t optimize them.\n",
    "- If possible, **always try to use built-in Spark SQL functions first** (they run faster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee2ad97b-1474-4843-a16f-0169d39fd2eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### UDF in PySpark\n",
    "\n",
    "PySpark UDFs are Python functions that you register so they can be used in Spark DataFrame transformations.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "- You define a Python function.\n",
    "- You use `pyspark.sql.functions.udf()` to convert it into a UDF.\n",
    "- You specify the return type.\n",
    "- You call it with `.withColumn()`, `.select()`, or `.filter()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aae8008-162d-4b98-ad23-30d7e247c840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Sample DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8d1f971-68ac-4eec-af98-0a6013ef3fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "data = [\n",
    "    (1, \"Alice\", 45),\n",
    "    (2, \"Bob\", 75),\n",
    "    (3, \"Charlie\", 30)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\", \"score\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bfd969c-b2c7-430d-918d-3b6a1b37e752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define a Python Function\n",
    "We want to label scores as \"Low\", \"Medium\", or \"High\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0093b75e-98b7-4455-be99-d080a15d0960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def label_score(score):\n",
    "    if score >= 70:\n",
    "        return \"High\"\n",
    "    elif score >= 40:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3abc15b0-2985-4d16-aad3-5cab39f62c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Register the UDF\n",
    "Import udf and StringType:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269cc200-f498-418c-ace5-5d4827db1672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "label_score_udf = udf(label_score, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02d5216e-2c52-48b6-9ec8-e3b187335358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use the UDF in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ddeaf3-1eaf-44d8-be94-4add5370a3fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_labeled = df.withColumn(\"score_label\", label_score_udf(df[\"score\"]))\n",
    "df_labeled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68460c21-d1a4-4769-a762-28e08da2b01c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What is a Pandas UDF?\n",
    "**Pandas UDFs** (also called _vectorized_ UDFs) are much faster than regular PySpark UDFs because they use Apache Arrow to efficiently transfer data between Spark and Python.\n",
    "\n",
    "- A Pandas UDF processes entire _batches_ (chunks) of data at once rather than one row at a time.\n",
    "- You write the logic using **Pandas Series** instead of single values.\n",
    "- Spark can parallelize and optimize them much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96d5ade8-8a3a-417c-b807-455eb130e5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define Pandas UDF\n",
    "Important:\n",
    "- Use pandas_udf decorator\n",
    "- Input: Pandas Series\n",
    "- Output: Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ca614a-3240-48e3-8e2f-b07e3822cc13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def label_score_pandas_udf(scores: pd.Series) -> pd.Series:\n",
    "    return scores.apply(\n",
    "        lambda s: \"High\" if s >= 70 else \"Medium\" if s >= 40 else \"Low\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "033d1ebe-25ce-4d74-8470-e2bb97d04b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Apply Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddcbe9dc-7ea8-4911-8932-57550b6fc7b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_labeled = df.withColumn(\"score_label\", label_score_pandas_udf(df[\"score\"]))\n",
    "df_labeled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa219e5a-309c-4500-974b-9b8de382d413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL UDFs\n",
    "\n",
    "SQL user-defined functions (UDFs) are a powerful feature that allows you to encapsulate custom logic inside a reusable SQL function.\n",
    "\n",
    "Unlike **external UDFs** (written in Python, Scala, Java, or R), SQL UDFs are defined purely in SQL. Because the logic is transparent to Spark's Catalyst Optimizer, **SQL UDFs usually perform better** on large datasets than external UDFs (which behave like opaque black boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab800e91-7513-40da-88d3-cd568f1f4c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating SQL UDFs\n",
    "To create a SQL UDF, you must define:\n",
    "\n",
    "- A `function name`\n",
    "- Optional `input parameters`\n",
    "- The `return data type`\n",
    "- A `SQL expression` that implements the function logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f1d8dd-db06-4c28-bc2a-3a8ce64d384a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Create a table with product discounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae4e037-b80b-4cdf-8ebb-eab1563a5cf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TEMP VIEW product_discounts AS\n",
    "SELECT * FROM VALUES\n",
    "  (101, 'Pencil', 15),\n",
    "  (102, 'Notebook', 45),\n",
    "  (103, 'Laptop', 75),\n",
    "  (104, 'Desk', 55)\n",
    "AS t(product_id, product_name, discount_percent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d40cf5-f632-4f9f-848e-31b3617f8758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create the UDF\n",
    "This UDF will return a string label for the discount level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61cf655b-8bfc-45db-8a2c-2dda345ce406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION discount_category(pct INT)\n",
    "RETURNS STRING\n",
    "RETURN\n",
    "  CASE\n",
    "    WHEN pct >= 70 THEN 'High'\n",
    "    WHEN pct >= 40 THEN 'Medium'\n",
    "    ELSE 'Low'\n",
    "  END;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86e1c34-6bab-4e96-b62d-8a4f06f1303f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Inspect the UDF\n",
    "You can describe the function metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34d6bced-690f-46eb-982b-fd16f0658f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DESCRIBE FUNCTION EXTENDED discount_category;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6183e53b-3831-4ade-8519-e1e470c904cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Apply the UDF in a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472ef817-e2f1-4539-97f0-da106b8bc8b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  product_id,\n",
    "  product_name,\n",
    "  discount_percent,\n",
    "  discount_category(discount_percent) AS discount_label\n",
    "FROM product_discounts\n",
    "ORDER BY product_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e69dd74-4962-4dea-ad15-a674e256dfc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Drop the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334c1a0a-ca19-44a8-9a2b-ebbfdb5e2947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DROP FUNCTION IF EXISTS discount_category;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SQL-UDF",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
