{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c47438ce-1b32-44c1-9a38-7b0f49adaa6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Joins in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c688d310-b344-4317-afd8-2e4ccdec8f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In PySpark, joins are a fundamental operation used to combine rows from two or more DataFrames based on a common column or key. This allows you to integrate data from different sources and perform complex analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6584c8a-9e03-4a32-99b4-15ccae55dac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Syntax\n",
    "```join(self, other, on=None, how=None)```\n",
    "\n",
    "**join()** operation takes parameters as below and returns DataFrame.\n",
    "\n",
    "- param **other**: Right side of the join\n",
    "- param **on**: a string for the join column name\n",
    "- param **how**: default *inner*. Must be one of *inner, cross, outer,full, full_outer, left, left_outer, right, right_outer,left_semi, and left_anti*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4c0ddd6-bb65-4868-a935-66402a84f52e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Let understand the type of Join with example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c0641be-5cf3-4fd2-919f-90c17b99aff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prapare data \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName('Join Example')\n",
    "         .getOrCreate())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7d16f4e-7387-49be-9748-9f3a6ac5b9d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp = [\n",
    "  (1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000),\n",
    "  (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000),\n",
    "  (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000),\n",
    "  (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000),\n",
    "  (5,\"Brown\",2,\"2010\",\"40\",\"\",-1),\n",
    "  (6,\"Brown\",2,\"2010\",\"50\",\"\",-1)\n",
    "]\n",
    "\n",
    "empColumns = [\"emp_id\",\"name\",\"manager_id\",\"doj\",\"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ce0fd17-9949-4bf8-a40b-9bef70040200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame(emp, schema=empColumns)\n",
    "emp_df.printSchema()\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dc4dd38-cbd1-4d0e-b606-e03431bba609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dept_df = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "dept_df.printSchema()\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "720f05c5-a81b-4413-b826-0ad29dfb0b03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inner Join:\n",
    "- Returns rows that have matching values in both DataFrames.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='inner')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af328ff-e565-4bbf-8cbb-e5bd8dc52ce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75bd1df2-91d2-4329-bbfa-c86872349f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(emp_df.join(\n",
    "    dept_df,\n",
    "    on = \"dept_id\",\n",
    "    how = \"inner\")\n",
    " .select('emp_id', 'name', dept_df.dept_id, 'dept_name')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a66e4b1-b429-41a5-833e-c191eb3d7ae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Left Outer Join:\n",
    "- Returns all rows from the left DataFrame and the matched rows from the right DataFrame.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='left')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "142c4934-e5d1-49b8-af90-ef6ad633efdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(emp_df.alias('e').join(\n",
    "    dept_df.alias('d'),\n",
    "    on = 'dept_id',\n",
    "    how = 'left')\n",
    " .select(\"e.emp_id\",'e.name','d.dept_id', 'd.dept_name')\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f3aceaa-323d-4a82-a2e9-62acff6d6f9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample DataFrames\n",
    "sales_data = [(1, \"2024-12-01\", 101, 500),\n",
    "              (2, \"2024-12-02\", 102, 300),\n",
    "              (3, \"2024-12-03\", 103, 700)]\n",
    "\n",
    "customer_data = [(101, \"Alice\"),\n",
    "                 (102, \"Bob\"),\n",
    "                 (104, \"Charlie\")]\n",
    "\n",
    "sales_columns = [\"sales_id\", \"date\", \"customer_id\", \"amount\"]\n",
    "customer_columns = [\"customer_id\", \"customer_name\"]\n",
    "\n",
    "# Create DataFrames\n",
    "sales_df = spark.createDataFrame(sales_data, sales_columns)\n",
    "customer_df = spark.createDataFrame(customer_data, customer_columns)\n",
    "\n",
    "# Perform Left Outer Join\n",
    "joined_df = (\n",
    "    sales_df.alias(\"s\")\n",
    "    .join(\n",
    "        customer_df.alias(\"c\"),\n",
    "        sales_df[\"customer_id\"] == customer_df[\"customer_id\"],\n",
    "        \"leftouter\"\n",
    "    )\n",
    "    .select(\"s.sales_id\", \"s.date\", \"c.customer_id\", \"s.amount\", \"c.customer_name\")\n",
    ")\n",
    "\n",
    "# Show the Result\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ee040dc-42b3-47cf-a474-6b918fa0c73f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Right Outer Join:\n",
    "- Returns all rows from the right DataFrame and the matched rows from the left DataFrame.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='right')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6444772-e35c-4eb8-bf01-97bb21aa17c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(emp_df.join(\n",
    "    dept_df,\n",
    "    emp_df.dept_id ==  dept_df.dept_id,\n",
    "    \"right\")\n",
    "   .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f7cfe3d-ed62-44fc-a88d-b907b846fd79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Full Outer Join:\n",
    "- Returns all rows from both DataFrames, joining them based on the common column.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='full')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9288ddcd-d70d-41df-8f08-84abfb82c5c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.join(\n",
    "    dept_df,\n",
    "    emp_df.dept_id ==  dept_df.dept_id,\n",
    "    how = \"outer\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a5f240-4fec-4546-a0c5-f9b1b77c4e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Left Semi Join:\n",
    "- Returns all rows only from the left DataFrame that have a match in the right DataFrame.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='leftsemi')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd13e041-cd78-4e45-a758-c89ee07af6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.join(\n",
    "    dept_df,\n",
    "    on = 'dept_id',\n",
    "    how = 'leftsemi') \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40541716-1f45-483f-844e-bc0683fa6bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Left Anti Join:\n",
    "- Returns all rows only from the left DataFrame that **do not** have a match in the right DataFrame.\n",
    "- **Syntax**: ```df1.join(df2, on='common_column', how='leftanti')```\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "348cc570-4ff6-4437-bd25-fc8b4bca6dd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.join(\n",
    "   dept_df,\n",
    "   on = 'dept_id',\n",
    "   how = 'leftanti') \\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a50da9d4-97ce-4583-99ce-3bd31da24d53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Self Join:\n",
    "- Join a dataframe to itself\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9e6feb-f98f-4e75-b0cf-6d9a2b624b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.alias(\"emp1\").join(\n",
    "    emp_df.alias(\"emp2\"),\n",
    "    on = col(\"emp1.manager_id\") == col(\"emp2.emp_id\"),\n",
    "    how = \"inner\") \\\n",
    "    .select(\n",
    "        col(\"emp1.emp_id\"),\n",
    "        col(\"emp1.name\"),\n",
    "        col(\"emp2.emp_id\").alias(\"manager_id\"),\n",
    "        col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
    "   .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Joins",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
