{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a920e814-8151-4fb3-bde0-e41d11ea0d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DataFrame Column Class\n",
    "\n",
    "**Data Source **\n",
    "* One hour of Pagecounts from the English Wikimedia projects captured August 5, 2016, at 12:00 PM UTC.\n",
    "* Size on Disk: ~23 MB\n",
    "* Type: Compressed Parquet File\n",
    "* More Info: <a href=\"https://dumps.wikimedia.org/other/pagecounts-raw\" target=\"_blank\">Page view statistics for Wikimedia projects</a>\n",
    "\n",
    "**Technical Accomplishments:**\n",
    "* Continue exploring the `DataFrame` set of APIs.\n",
    "* Introduce the `Column` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f47adb3c-f864-4204-b3ac-f5b94012d6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f5dcab-94e5-4281-b534-4bd23b830e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Read CSV Data\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c01348-556e-4158-99b2-01af569a4f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Data Source\n",
    "\n",
    "We will be using the same data source as our previous notebook.\n",
    "\n",
    "As such, we can go ahead and start by creating our initial `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cad42f8f-db18-4b2d-a324-ae9ed06bb535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../MountDatasetSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9632474-1a71-46b6-890c-4db6f2b2659e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parquetDir = \"/mnt/files/dataset/pagecounts/staging_parquet_en_only_clean/\"\n",
    "pagecountsEnAllDF = spark.read.parquet(parquetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fd3e649-781d-40d5-85d7-66827ad4f419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total = pagecountsEnAllDF.count()\n",
    "print(\"Record Count: {0:,}\".format( total ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02b8ec9f-12a7-459c-8ba3-4a0ffb62c597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now let's take another peek at our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bfdf817-350c-496b-84bc-5a1ea52e7d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pagecountsEnAllDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b637d7e-8a71-4f30-88d5-c505303025e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As we view the data, we can see that there is no real rhyme or reason as to how the data is sorted.\n",
    "* We cannot even tell if the column **project** is sorted - we are seeing only the first 1,000 of some 2.3 million records.\n",
    "* The column **article** is not sorted as evident by the article **A_Little_Boy_Lost** appearing between a bunch of articles starting with numbers and symbols.\n",
    "* The column **requests** is clearly not sorted.\n",
    "* And our **bytes_served** contains nothing but zeros.\n",
    "\n",
    "So let's start by sorting our data. In doing this, we can answer the following question:\n",
    "\n",
    "What are the top 10 most requested articles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "923160f9-adfe-4d00-9053-64f46afbcfd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## orderBy(..) & sort(..)\n",
    "\n",
    "If you look at the API docs, `orderBy(..)` is described like this:\n",
    "> Returns a new Dataset sorted by the given expressions.\n",
    "\n",
    "Both `orderBy(..)` and `sort(..)` arrange all the records in the `DataFrame` as specified.\n",
    "* Like `distinct()` and `dropDuplicates()`, `sort(..)` and `orderBy(..)` are aliases for each other.\n",
    "  * `sort(..)` appealing to functional programmers.\n",
    "  * `orderBy(..)` appealing to developers with an SQL background.\n",
    "* Like `orderBy(..)` there are two variants of these two methods:\n",
    "  * `orderBy(Column)`\n",
    "  * `orderBy(String)`\n",
    "  * `sort(Column)`\n",
    "  * `sort(String)`\n",
    "\n",
    "All we need to do now is sort our previous `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fc9ae8c-0300-47da-ac40-a86b83275539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sortedDF = (pagecountsEnAllDF\n",
    "  .orderBy(\"requests\")\n",
    ")\n",
    "sortedDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37944aa5-3613-46f3-826c-813fd3f605c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As you can see, we are not sorting correctly.\n",
    "\n",
    "We need to reverse the sort.\n",
    "\n",
    "One might conclude that we could make a call like this:\n",
    "\n",
    "`pagecountsEnAllDF.orderBy(\"requests desc\")`\n",
    "\n",
    "Try it in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6872ae9d-1939-4c62-b6fc-2e126b4c5719",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and try this:\n",
    "# pagecountsEnAllDF.orderBy(\"requests desc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b76ac9ae-f561-43df-a961-826f6301b3f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Why does this not work?\n",
    "* The `DataFrames` API is built upon an SQL engine.\n",
    "* There is a lot of familiarity with this API and SQL syntax in general.\n",
    "* The problem is that `orderBy(..)` expects the name of the column.\n",
    "* What we specified was an SQL expression in the form of **requests desc**.\n",
    "* What we need is a way to programmatically express such an expression.\n",
    "* This leads us to the second variant, `orderBy(Column)` and more specifically, the class `Column`.\n",
    "\n",
    "** *Note:* ** *Some of the calls in the `DataFrames` API actually accept SQL expressions.*<br/>\n",
    "*While these functions will appear in the docs as `someFunc(String)` it's very*<br>\n",
    "*important to thoroughly read and understand what the parameter actually represents.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fe09283-ac08-42ab-beaf-54282edf62d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Column Class\n",
    "\n",
    "The `Column` class is an object that encompasses more than just the name of the column, but also column-level-transformations, such as sorting in a descending order.\n",
    "\n",
    "The first question to ask is how do I create a `Column` object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0e26f1c-643b-41e2-8857-affc37a7c709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In Python we have these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df2af883-83c1-4448-8626-b47fef94d2f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scala & Python both support accessing a column from a known DataFrame\n",
    "# Uncomment this if you are using the Python version of this notebook\n",
    "columnA = pagecountsEnAllDF[\"requests\"]\n",
    "\n",
    "# If we import ...sql.functions, we get a couple of more options:\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# This uses the col(..) function\n",
    "columnC = col(\"requests\")\n",
    "\n",
    "# This uses the expr(..) function which parses an SQL Expression\n",
    "columnD = expr(\"a + 1\")\n",
    "\n",
    "# This uses the lit(..) to create a literal (constant) value.\n",
    "columnE = lit(\"abc\")\n",
    "\n",
    "# Print the type of each attribute\n",
    "print(\"columnA: {}\".format(columnA))\n",
    "print(\"columnC: {}\".format(columnC))\n",
    "print(\"columnD: {}\".format(columnD))\n",
    "print(\"columnE: {}\".format(columnE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a0702be-47e3-4bac-aea1-3aa3cf49f1b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "In the case of Scala, the cleanest version is the **$\"column-name\"** variant.\n",
    "\n",
    "In the case of Python, the cleanest version is the **col(\"column-name\")** variant.\n",
    "\n",
    "So with that, we can now create a `Column` object, and apply the `desc()` operation to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c54e064-9313-4b86-b687-596072011609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "column = col(\"requests\").desc()\n",
    "\n",
    "# Print the column type\n",
    "print(\"column:\", column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3583c766-ce14-4051-835b-698e97f88fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "And now we can piece it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a6fef7-c3b6-4951-a839-4eb5177e8d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sortedDescDF = (pagecountsEnAllDF\n",
    "  .orderBy( col(\"requests\").desc() )\n",
    ")  \n",
    "sortedDescDF.show(10, False) # The top 10 is good enough for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2faff71b-fde8-48e2-8a12-cac6c3d67285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It should be of no surprise that the **Main_Page** (in both the Wikipedia and Wikimedia projects) is the most requested page.\n",
    "\n",
    "Followed shortly after that is **Special:Search**, Wikipedia's search page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcc8a54f-64e0-48e5-8094-0b68f648bb47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Review Column Class\n",
    "\n",
    "The `Column` objects provide us a programmatic way to build up SQL-ish expressions.\n",
    "\n",
    "Besides the `Column.desc()` operation we used above, we have a number of other operations that can be performed on a `Column` object.\n",
    "\n",
    "Here is a preview of the various functions - we will cover many of these as we progress through the class:\n",
    "\n",
    "**Column Functions**\n",
    "* Various mathematical functions such as add, subtract, multiply & divide\n",
    "* Various bitwise operators such as AND, OR & XOR\n",
    "* Various null tests such as `isNull()`, `isNotNull()` & `isNaN()`.\n",
    "* `as(..)`, `alias(..)` & `name(..)` - Returns this column aliased with a new name or names (in the case of expressions that return more than one column, such as explode).\n",
    "* `between(..)` - A boolean expression that is evaluated to true if the value of this expression is between the given columns.\n",
    "* `cast(..)` & `astype(..)` - Convert the column into type dataType.\n",
    "* `asc(..)` - Returns a sort expression based on the ascending order of the given column name.\n",
    "* `desc(..)` - Returns a sort expression based on the descending order of the given column name.\n",
    "* `startswith(..)` - String starts with.\n",
    "* `endswith(..)` - String ends with another string literal.\n",
    "* `isin(..)` - A boolean expression that is evaluated to true if the value of this expression is contained by the evaluated values of the arguments.\n",
    "* `like(..)` - SQL like expression\n",
    "* `rlike(..)` - SQL RLIKE expression (LIKE with Regex).\n",
    "* `substr(..)` - An expression that returns a substring.\n",
    "* `when(..)` & `otherwise(..)` - Evaluates a list of conditions and returns one of multiple possible result expressions.\n",
    "\n",
    "The complete list of functions differs from language to language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94b9e02c-e78c-4eec-b6f2-8a3a2514bafb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pagecountsEnAllDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2945e7ce-c014-435f-a06d-4242d3721610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  col(\"project\"),\n",
    "  col(\"article\"),\n",
    "  (col(\"requests\") + 100).alias(\"requests_plus_100\"),\n",
    "  (col(\"bytes_served\") + 500).alias(\"bytes_plus_500\"),\n",
    "  (col(\"requests\") - 50).alias(\"requests_minus_50\"),\n",
    "  (col(\"bytes_served\") / 1000).alias(\"kb_served\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1db91d99-23a2-482d-abc7-e332e4777251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Null tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c08e4cfb-374d-46cc-975b-57fbc9acfef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  col(\"article\"),\n",
    "  col(\"article\").isNull().alias(\"article_is_null\"),\n",
    "  col(\"article\").isNotNull().alias(\"article_is_not_null\"),\n",
    "  isnan(col(\"requests\").cast(\"double\")).alias(\"requests_is_nan\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65043d3-a951-469e-9fe1-c8f052ff669d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63cd8280-5d23-4c1d-89f4-d162ea0611e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  col(\"project\").alias(\"proj\").name(\"proj_named\"),\n",
    "  col(\"article\").alias(\"art\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8111aec6-86c6-48bc-8cc3-b58a87ec2c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a035612b-c1b8-44c5-be25-52eb9672d329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  col(\"requests\"),\n",
    "  col(\"requests\").between(100, 300).alias(\"requests_between_100_300\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4d0322a-ee6a-4428-85da-6e6f1555015e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a0d233-431d-4065-9f60-5008cdeb9206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  col(\"requests\"),\n",
    "  col(\"requests\").cast(\"double\").alias(\"requests_double\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce377b0c-bf44-40f1-b9a3-b18aaa9da22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### String startswith and endswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30dc45cb-98f9-45bc-8d03-59eb5a767cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.filter(\n",
    "  (col(\"article\").startswith(\"Tr\")) & (col(\"article\").endswith(\"age\"))\n",
    ").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5913f24-0a76-4eb5-a71b-526b7c43f4e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef6d0458-5a8a-48ff-ba15-3340e3aed6ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.filter(\n",
    "  col(\"project\").isin(\"en\", \"fr\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0418370-98b2-484d-a213-233d87d39edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### when and otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9138ead-d483-441a-9c12-6eb08074985a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\n",
    "  when(col(\"requests\") < 100, \"Low\")\n",
    "   .when((col(\"requests\") >= 100) & (col(\"requests\") <= 300), \"Medium\")\n",
    "   .otherwise(\"High\").alias(\"request_category\") \n",
    ").groupBy(\"request_category\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0e3c246-9776-4189-b70b-989fc4b38d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### filter(..) & where(..) w/SQL Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d2768f5-412c-4700-926e-9c1a92e92736",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "whereDF = (sortedDescDF\n",
    "  .where( \"project = 'en'\" )\n",
    ")\n",
    "whereDF.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23396c86-f736-41ff-9fcb-d565023c10fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "whereDF = (sortedDescDF\n",
    "  .where( col(\"project\") == \"en\" )\n",
    ")\n",
    "whereDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3460e26-9b70-4330-83e7-243f44aa5e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now that we are only looking at the main Wikipedia articles, we get a better picture of the most popular articles on Wikipedia.\n",
    "\n",
    "Next, let's take a look at the second variant that takes a `Column` object as its first parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93de9add-a386-4815-96f1-fbb9e5e32227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### filter(..) & where(..) w/Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39fa8e2d-e2fb-496e-8642-921e30ce5990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filteredDF = (sortedDescDF\n",
    "  .filter( col(\"project\") == \"en\")\n",
    ")\n",
    "filteredDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "178f9f04-baef-41e2-a85a-770fa3119fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### The Solution..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e3dee62-3397-423c-8cd3-d7042fc448de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "With that behind us, we can clearly **see** the top ten most requested articles.\n",
    "\n",
    "But what if we need to **programmatically** extract the value of the most requested article's name and its number of requests?\n",
    "\n",
    "That is to say, how do we get the first record, and from there...\n",
    "* the value of the second column, **article**, as a string...\n",
    "* the value of the third column, **requests**, as an integer...\n",
    "\n",
    "Before we proceed, let's apply another filter to get rid of **Main_Page** and anything starting with **Special:** - they're just noise to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c0b944-84f4-4644-8dcd-6e283ccec9e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "articlesDF = (filteredDF\n",
    "  .drop(\"bytes_served\")\n",
    "  .filter( col(\"article\") != \"Main_Page\")\n",
    "  .filter( col(\"article\") != \"-\")\n",
    "  .filter( col(\"article\").startswith(\"Special:\") == False)\n",
    ")\n",
    "articlesDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d19bcbe-a160-4fdc-8b15-c3e9532cdbf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## first() & head()\n",
    "\n",
    "If you look at the API docs, both `first(..)` and `head(..)` are described like this:\n",
    "> Returns the first row.\n",
    "\n",
    "Just like `distinct()` & `dropDuplicates()` are aliases for each other, so are `first(..)` and `head(..)`.\n",
    "\n",
    "However, unlike `distinct()` & `dropDuplicates()` which are **transformations** `first(..)` and `head(..)` are **actions**.\n",
    "\n",
    "Once all processing is done, these methods return the object backing the first record.\n",
    "\n",
    "In the case of `DataFrames` (both Scala and Python) that object is a `Row`.\n",
    "\n",
    "In the case of `Datasets` (the strongly typed version of `DataFrames` in Scala and Java), the object may be a `Row`, a `String`, a `Customer`, a `PendingApplication` or any number of custom objects.\n",
    "\n",
    "Focusing strictly on the `DataFrame` API for now, let's take a look at a call with `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5610707a-7dd8-4189-ab66-94f75741d8c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "firstRow = articlesDF.first()\n",
    "\n",
    "print(firstRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75f2b6eb-dff8-413a-80ce-934c5fdcae61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Row Class\n",
    "\n",
    "Now that we have a reference to the object backing the first row (or any row), we can use it to extract the data for each column.\n",
    "\n",
    "Before we do, let's take a look at the API docs for the `Row` class.\n",
    "\n",
    "We can now put it all together to get the number of requests for the most requested project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c41c214b-6713-4c86-a09d-bfeb9c548e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "article = firstRow['article']\n",
    "total = firstRow['requests']\n",
    "\n",
    "print(\"Most Requested Article: \\\"{0}\\\" with {1:,} requests\".format( article, total ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8675145-b8d3-4db9-9854-2254e49fe97b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## collect()\n",
    "\n",
    "If you look at the API docs, `collect(..)` is described like this:\n",
    "> Returns an array that contains all of Rows in this Dataset.\n",
    "\n",
    "`collect()` returns a collection of the specific type backing each record of the `DataFrame`.\n",
    "* In the case of Python, this is always the `Row` object.\n",
    "* In the case of Scala, this is also a `Row` object.\n",
    "* If the `DataFrame` was converted to a `Dataset` the backing object would be the user-specified object.\n",
    "\n",
    "Building on our last example, let's take the top 10 records and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f70ed97-2610-44be-a65f-34abf19652ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rows = (articlesDF\n",
    "  .limit(10)           # We only want the first 10 records.\n",
    "  .collect()           # The action returning all records in the DataFrame\n",
    ")\n",
    "\n",
    "# rows is an Array. Now in the driver, \n",
    "# we can just loop over the array and print 'em out.\n",
    "\n",
    "listItems = \"\"\n",
    "for row in rows:\n",
    "  project = row['article']\n",
    "  total = row['requests']\n",
    "  listItems += \"    <li><b>{}</b> {:0,d} requests</li>\\n\".format(project, total)\n",
    "  \n",
    "html = \"\"\"\n",
    "<body>\n",
    "  <h1>Top 10 Articles</h1>\n",
    "  <ol>\n",
    "    %s\n",
    "  </ol>\n",
    "</body>\n",
    "\"\"\" % (listItems.strip())\n",
    "\n",
    "displayHTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "088f7b6f-a08a-4bc0-af18-6dd60890dd24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## take(n)\n",
    "\n",
    "If you look at the API docs, `take(n)` is described like this:\n",
    "> Returns the first n rows in the Dataset.\n",
    "\n",
    "`take(n)` returns a collection of the first N records of the specific type backing each record of the `DataFrame`.\n",
    "* In the case of Python, this is always the `Row` object.\n",
    "* In the case of Scala, this is also a `Row` object.\n",
    "* If the `DataFrame` was converted to a `Dataset` the backing object would be the user-specified object.\n",
    "\n",
    "In short, it's the same basic function as `collect()` except you specify as the first parameter the number of records to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c372d9d-1f9b-400c-b1a0-d0d5978a588b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rows = articlesDF.take(10)\n",
    "\n",
    "# rows is an Array. Now in the driver, \n",
    "# we can just loop over the array and print 'em out.\n",
    "\n",
    "listItems = \"\"\n",
    "for row in rows:\n",
    "  project = row['article']\n",
    "  total = row['requests']\n",
    "  listItems += \"    <li><b>{}</b> {:0,d} requests</li>\\n\".format(project, total)\n",
    "  \n",
    "html = \"\"\"\n",
    "<body>\n",
    "  <h1>Top 10 Articles</h1>\n",
    "  <ol>\n",
    "    %s\n",
    "  </ol>\n",
    "</body>\n",
    "\"\"\" % (listItems.strip())\n",
    "\n",
    "# UNCOMMENT FOR A PRETTIER PRESENTATION\n",
    "displayHTML(html)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Column-Class",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
